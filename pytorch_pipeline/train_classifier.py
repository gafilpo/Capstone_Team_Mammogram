"""train_classifier.ipynb

Automatically generated by Colaboratory.


# Initialization
"""

# Mount drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# Set up base path
import os
import numpy as np
import pandas as pd

BASE_PATH = "/content/gdrive/MyDrive/Capstone/Project"

# %cd $BASE_PATH

"""# Configs"""

# Configs to change

EXP_DIR = "" # experiment directory
DATASET_NAME = "images_resized"  # name of (zip) folder containing your data
NUM_CLASSES = 1 # number of classes
METADATA = pd.read_csv("metadata.csv")
SUPPLEMENTAL_POS = "supplemental_pos"

# Fixed configs (change for experimentations only)

# Datasets configs
TRAIN_SPLIT_NAME = "train.csv"
VAL_SPLIT_NAME = "val.csv"
TRAIN_VAL_SPLIT = 0.9

# Model configs
INPUT_IMAGE_SIZE_W = 480
INPUT_IMAGE_SIZE_H = 640
BACKBONE = "r101"

MODEL_CONFIGS = {
    "input_image_size_w": INPUT_IMAGE_SIZE_W,
    "input_image_size_h": INPUT_IMAGE_SIZE_H,
    "num_classes": NUM_CLASSES,
    "backbone": BACKBONE,
    "pretrained": True
}

# Training configs
DESC = "training" # experiment description
TRAIN_CONFIGS = {
    "dataset": {
        "training_split": os.path.join(BASE_PATH, EXP_DIR, TRAIN_SPLIT_NAME),
        "validation_split": os.path.join(BASE_PATH, EXP_DIR, VAL_SPLIT_NAME),
    },

    "training_parameters": {
        "num_epochs": 15,
        "batch_size": 8,
        "base_lr": 0.001,
        "device": 'cuda:0',
        "starting_ckpt": None,
    }
}

# Note: configs like optimizer, criterion and schedulers are set inside Trainer class

"""# Training"""

# Unzip dataset
#!unzip "{BASE_PATH}{EXP_DIR}/{DATASET_NAME}.zip" -d "{BASE_PATH}/{EXP_DIR}"

# Check number of images is correct (sometimes Colab doesn't unzip correctly)
!ls {DATASET_NAME} |wc -l

import create_splits
import network
import dataset
import train


# Create training and validation splits and return training weights (negative / positive ratio)
train_weights = create_splits.create_splits(
    exp_dir = BASE_PATH,
    dataset_name = DATASET_NAME,
    supplemental_pos = SUPPLEMENTAL_POS,
    metadata = METADATA,
    train_val_split = TRAIN_VAL_SPLIT,
    train_split_name = TRAIN_SPLIT_NAME,
    val_split_name = VAL_SPLIT_NAME,
)

# Train

DESC = f"training_{BACKBONE}" # experiment description

trainer = train.Trainer(model_configs=MODEL_CONFIGS,
                        train_configs=TRAIN_CONFIGS,
                        exp_dir=os.path.join(BASE_PATH, EXP_DIR),
                        train_weights=train_weights,
                        desc=DESC)

trainer.train()


"""# Evaluation"""

eval_dataset = dataset.ClassificationDataset(
    "val.csv",
    INPUT_IMAGE_SIZE_W,
    INPUT_IMAGE_SIZE_H,
    is_train=False,
)

dataloader = torch.utils.data.DataLoader(
    eval_dataset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True
)

def evaluate(model, dataloader, threshold=0.5, device='cuda:0'):
    """Evaluate model --> compute accuracy, precision, recall and F1-score."""
    model.eval()

    n_batches = len(dataloader)

    loss_sum = 0
    all_labels = []
    all_preds = []
    all_probas = []
    categories = ["negative", "positive"]
    for i, batch in tqdm(enumerate(dataloader), total=n_batches, desc="Validation"):
        images = batch["image"].to(device=device)
        labels = batch["label"].to(device=device)

        with torch.no_grad():
            _, probas = model(images)
            preds = (probas > threshold)

        all_labels += labels.tolist()
        all_preds += preds.tolist()
        all_probas += probas.tolist()

    print(all_labels)
    print(all_preds)
    print(all_probas)
    cls_report = metrics.classification_report(
        all_labels, all_preds, target_names=categories, zero_division=0
    )

    print(cls_report)

    prec, rec, f1, _ = metrics.precision_recall_fscore_support(
        all_labels, all_preds, average=None, labels=[0, 1], zero_division=0
    )

    accuracy = (np.array(all_labels) == np.array(all_preds)).sum() / len(all_labels)

    mean_loss = loss_sum / n_batches

    return accuracy, prec, rec, f1, all_probas, all_labels

models_paths = [('../best_resnet18.pt', 'r18'), 
                ('../best_resnet34.pt', 'r34'),
                ('../best_resnet50.pt', 'r50'),
                ('../best_resnet101.pt', 'r101')]

eval_list = []

for m in models_paths:

  BACKBONE = m[1]

  MODEL_CONFIGS = {
    "input_image_size_w": INPUT_IMAGE_SIZE_W,
    "input_image_size_h": INPUT_IMAGE_SIZE_H,
    "num_classes": NUM_CLASSES,
    "backbone": BACKBONE,
    "pretrained": True}
    
  model = ClassificationModel(**MODEL_CONFIGS)
  model.to(device='cuda:0')
  ckpt = torch.load(m[0])
  model.load_state_dict(ckpt["model"])
  eval_list.append(evaluate(model, dataloader, threshold=0.5))


"""# Figures"""

# Plotting ROC curve for each of the ResNets

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
plot_list = list(zip(eval_list, ['ResNet18', 'ResNet34', 'ResNet50', 'ResNet101'],
                     ['grey', 'pink', 'blue', 'lightblue']))
fig, ax = plt.subplots(figsize=(8,6))
for k in range(0, 4):
  fpr, tpr, _ = metrics.roc_curve(plot_list[k][0][5], plot_list[k][0][4])
  auc = metrics.roc_auc_score(plot_list[k][0][5], plot_list[k][0][4])
ax.plot(fpr, tpr, label=f"{plot_list[k][1]} AUC="+str(round(auc, 4)), c=plot_list[k][2])
ax.plot([0, 1], [0, 1],'r--', label='Skilless Classifier')
ax.set_ylabel('True Positive Rate')
ax.set_xlabel('False Positive Rate')
ax.set_title('ROC: ResNets')
ax.legend(loc=4)
plt.show()

#Plotting Precision Recall Curve for the best ResNet50

from sklearn.metrics import precision_recall_curve
precision, recall, thresholds = precision_recall_curve(eval_list[2][5], eval_list[2][4])
no_skill = sum(evaluation[5]) / len(evaluation[5])
plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='Skilless Classifier')
plt.plot(recall[:-5], precision[:-5], label='ResNet50')
plt.legend()
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('ResNet50: Precision Recall Curve');

#Plotting the f1 score vs. decision thresholds for the best ResNet50

from sklearn.metrics import f1_score
f1_scores = [f1_score(eval_list[2][5], eval_list[2][4] >= t) for t in thresholds]
plt.plot(thresholds, f1_scores)
plt.xlabel('Threshold')
plt.ylabel('F1 score')
plt.title('ResNet50: f1 score at different decision thresholds')
plt.show()

#Plotting negative and positive examples for breast tissue density A
from PIL import Image

img1 = Image.open('../1086977375.png').resize((200, 220))
img2 = Image.open('../1417771843.png').resize((200, 220))
img3 = Image.open('../1567534278.png').resize((200, 220))
img4 = Image.open('../2113382962.png').resize((200, 220))

fig, axs = plt.subplots(1, 4, figsize=(12, 5))

axs[0].imshow(img1)
axs[0].set_title('Positive: Density A MLO')
axs[1].imshow(img2)
axs[1].set_title('Positive: Density A CC')
axs[2].imshow(img3)
axs[2].set_title('Negative: Density A MLO')
axs[3].imshow(img4)
axs[3].set_title('Negative: Density A CC');

#Plotting negative and positive examples for breast tissue density D
img1 = Image.open('../1531879119.png').resize((200, 220))
img2 = Image.open('../1593856707.png').resize((200, 220))
img3 = Image.open('../1680691634.png').resize((200, 220))
img4 = Image.open('../353346201.png').resize((200, 220))

fig, axs = plt.subplots(1, 4, figsize=(12, 5))

axs[0].imshow(img1)
axs[0].set_title('Positive: Density D MLO')
axs[1].imshow(img2)
axs[1].set_title('Positive: Density D CC')
axs[2].imshow(img3)
axs[2].set_title('Negative: Density D MLO')
axs[3].imshow(img4)
axs[3].set_title('Negative: Density D CC');
